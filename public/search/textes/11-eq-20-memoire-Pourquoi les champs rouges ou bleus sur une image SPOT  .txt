Images, couleurs, vision…
Ce que nous voyons

Ce que « voit » SPOT

Il semblerait que nos yeux et ceux de SPOT soient différents !

I ) Qu’appelle -t-on « voir » ?
Les objets éclairés par le soleil renvoient de la lumière dans toutes les directions.
Pour y « voir », SPOT effectue des mesures de cette lumière « renvoyée » et à partir de
ces résultats de mesure, nous sommes en mesure d’afficher une image satellite.
Quand nous regardons un objet, nos yeux effectuent eux aussi des mesures de lumière
renvoyée par l’objet et transmettent les résultats des mesures à notre cerveau qui les
utilisent pour fabriquer une image que nous « voyons ».

II ) La lumière
La lumière que nous appelons lumière du jour est la lumière émise par le Soleil : elle se
propage du Soleil jusqu’à la Terre à la vitesse de 300000 km/s (il lui faut 8 minutes pour
venir du Soleil jusque notre planète ; si le Soleil s’éteignait brusquement, les habitants
de la Terre ne s’en rendraient compte que 8 minutes plus tard !).
Cette lumière se propage en ligne droite du Soleil jusqu’à nous et, bien que le Soleil
émette de la lumière dans toutes les directions (comme le montrent les dessins
d’enfants !), notre planète est si petite comparée à cette étoile et si éloignée d’elle, que les
rayons nous parvenant peuvent être considérés comme étant parallèles entre eux.

Un vrai Soleil !

La réalité !

La Terre

Sur cette image agrandie, on
constate que les rayons du Soleil
paraissent parallèles entre eux.

La lumière se propage en ligne droite, mais elle peut changer de direction : voyez ce que
l’on peut faire en classe avec un simple miroir ou le verre d’une montre !

Soleil

Œil du professeur
Ce schéma correspond au
phénomène de réflexion de la
lumière.
Miroir ou montre

Il existe un deuxième moyen de changer la direction de propagation de la lumière :
utiliser le phénomène de réfraction, c’est-à-dire, amener la lumière à se propager dans
deux milieux différents (tous deux transparents, quand même : il faut que la lumière
traverse les deux milieux).

Air

Eau

D

Lors du passage d’un milieu transparent à un
autre, la lumière change de direction : c’est le
phénomène de réfraction.
Entre la direction d’où arrive la lumière
(rayon incident) et la direction prise par la
lumière dans l’eau (rayon réfracté), il existe
un angle D, appelé angle de déviation.

Mais là, les choses se compliquent !
Au lieu d’envoyer des rayons lumineux quelconques, envoyons de la lumière émise par
une diode électroluminescente rouge puis par une verte.

Air

Air

Eau

Eau

La lumière rouge et la lumière verte ont une ou des propriétés différentes : l’angle D rouge
et D vert sont différents.
Quelle grandeur caractérise la couleur de la lumière ?
La lumière est une vibration à la fois électrique et magnétique : on la désigne sous le
nom d’onde électromagné tique.
Une onde électromagnétique est caractérisée par sa longueur d’onde.
A une longueur d’onde correspond une couleur : on a une radiation lumineuse
monochromatique (les diodes électroluminescentes émettent des radiations
monochromatiques). Par contre, à une couleur peuvent correspondre plusieurs
longueurs d’onde, les radiations peuvent s’ajouter: on observe de la lumière composée.

Air

Eau

Par exemple, une lumière jaune peut être
composée d’une radiation rouge et d’une
radiation verte. Au passage d’un milieu à un
autre, les deux lumières monochromatiques sont
déviées différemment.
Cependant, on peut aussi observer une lumière
jaune monochromatique, celle d’une diode
électroluminescente jaune par exemple et dans ce
cas on obtiendra le même schéma que dans les cas
de lumières issues de diodes électroluminesce ntes
verte ou rouge, avec un angle de déviation
caractéristique de la lumière monochromatique
jaune.

Le soleil émet des radiations de différentes longueurs d’onde. Le passage de la lumière
du soleil de l’air à l’eau, puis de l’eau à l’air lors de la traversée d’une goutte d’eau fait
que les différentes radiations monochromatiques sont déviées d’un angle différent et on
peut observer (dans certaines conditions) un arc-en-ciel.
Le domaine des ondes électromagnétiques est très vaste ; toutes ces ondes sont
caractérisées par leur longueur d’onde ; la lumière visible est un sous -ensemble de

l’ensemble des ondes électromagnétiques. Les longueurs d’onde de la lumière visible
sont comprises entre 400 et 800 nm.

III ) Comment voit-on la lumière ?
Que l’on soit un être humain ou un satellite d’observation de la Terre, on utilise des
capteurs qui mesurent l’énergie lumineuse reçue et envoient le résultats de cette mesure
à un système capable d’utiliser l’ensemble de ces résultats pour fabriquer une image : le
cerveau pour l’être humain, un ordinateur équipé d’un logiciel spécialisé pour SPOT.
La lumière pouvant être la somme de diverses radiations, les capteurs de lumière sont
spécialisés : certains ne voient que du ro uge, d’autres ne voient que du bleu, etc. Ces
capteurs sont associés à des filtres sélectifs .
a) L’œil humain
L’étude de l’œil humain montre que nos yeux possèdent différents capteurs de lumière
implantés dans la rétine : des capteurs en forme de bâtonnets et des capteurs en forme
de cônes.
Coupe de la rétine

Les bâtonnets ne sont pas sélectifs et mesurent l’énergie lumineuse reçue dans sa totalité.
Ils nous permettent de savoir si l’objet observé est très lumineux ou peu lumineux, mais
ne nous permettent pas de le voir en couleurs, les objets sont vus en différentes nuances
de gris, mais comme ces capteurs sont très sensibles à la quantité d’énergie reçue, ils
sont saturés quand la lumière est intense et dans ce cas, ce sont les informations
transmises par les cônes qu’utilise notre cerveau. Par contre, ils nous permettent de voir
dans la pénombre ou la nuit.
Les cônes sont des capteurs sélectifs, ils ne voient qu’une couleur (en fait ils sont
sensibles à l’ensemble du spectre visible mais leur sensibilité est maximale pour une
bande de longueurs d’onde correspondant à une couleur donnée, si bien que les autres
couleurs peuvent être considérées comme non-vues).

Par contre, nos yeux ne possèdent pas autant de cônes que de couleurs visibles. Seules
trois couleurs sont mesurées par les capteurs de notre rétine : le bleu, le vert et le rouge.

Sensibilité des capteurs de l’œil
humain suivant les longueurs
d’onde
des
radiations
lumineuses (notre œil ne paraît
guère sensible au bleu mais
notre cerveau effectue les
corrections nécessaires).

b) L’œil de SPOT :
Barrette de capteurs CCD
(correspondant aux cônes
et bâtonnets de notre oeil)

Lentille (correspondant au
cristallin de notre œil)
Le déplacement
du satellite.

3000 points de mesure
correspondent à une ligne de
3000 éléments de 20 m de
largeur, ce qui correspond à
une scène de 60 km de large.

Les éléments de la barrette de
capteurs enregistrent des mesures
sur une ligne de 3000 points durant
le temps nécessaire pour que la trace
au sol se déplace de 20 m.

L’ «oeil» de SPOT peut regarder «sur le côté»
comme notre œil : un miroir orientable et son
actionneur correspondent aux muscles qui
nous permettent de regarder à droite ou à
gauche sans tourner la tête.
Mais, alors que le système
optique
de
notre
œil
correspond à une simple
lentille (le cristallin), le
système optique de SPOT
est un télescope (il faut
orienter et concentrer la
lumière par un assemblage
de lentilles et miroirs.).
Le satellite possède trois sortes de capteurs (comme notre œil possède trois sortes de
cônes).
Dans chaque série de capteurs, les photorécepteurs sont sensibles à des radiations
lumineuses correspondant à un domaine de longueurs d’onde ; ce domaine est appelé
canal.
Canal 1 appelé XS1 : de 500 nm à 590 nm (vert).
Canal 2 appelé XS2 : de 610 nm à 680 nm (rouge).
Canal 3 appelé XS3 : de 790 nm à 890 nm (infrarouge).
Les récepteurs embarqués sur les satellites sont des capteurs CCD (comme dans les
camescopes numériques) mais nous allons étudier le principe des mesures effectuées par
SPOT en prenant comme capteurs de lumière des photodiodes.
c) Comparaison capteurs œil humain / capteurs œil SPOT

Vert
400

500

Infra
rouge

Rouge
600

longueur d’onde (nm)

700

800

900

IV ) Etude d’une photodiode
EA0

+
2.5V
0

-

I

10 k ?

2.5V

R 1 k?
RI

V

EA7

E
Ud

Ref
Le montage ci-dessus permet de relever les caractéristiques intensité/tens ion de la
photodiode pour différents éclairements.
I

Courbe obtenue
dans l’obscurité
Ud
Augmentation
de l’éclairement

La mesure de l’intensité du courant
dans ce domaine permet de mesurer
l’éclairement
(principe
d’un
luxmètre).

V ) Capteur de lumière sélectif
On place des filtres devant la photodiode.
Par exemple avec un filtre qui laisse passer le rouge et l’infrarouge associé à un filtre qui
arrête l’infrarouge, on obtient un capteur de lumière qui ne « voit » que le rouge.

200

300

400

500

600

700

800

900

En suivant le même principe, on obtient 4 capteurs de lumière :
Capteur bleu pour l’œil humain
Capteur vert pour l’œil humain et l’œil de SPOT
Capteur rouge pour l’œil humain et l’œil de SPOT
Capteur infrarouge pour l’œil de SPOT

VI ) L’ensemble ANACHROM : capteurs sélectifs, interface
ORPHY et logiciel

Résultats
des mesures

Observation de feuilles
vertes avec ANACHROM

VII ) Obtention d’une image sur un écran
a) Principe d’un écran
Un écran comporte, sur sa face intérieure, de nombreux éléments, constitué chacun de
trois pastilles capable d’émettre de la lumière rouge, verte ou bleue quand elles sont
frappées par un faisceau d’électrons.
L’intensité de la lumière émise dépend de l’intensité du faisceau issu des différents
canons à électrons.
Lorsqu’on regarde l’écran d’assez loin, les trois couleurs de l’élément se fondent en une
seule : elles « s’ajoutent » (synthèse additive).

Si il n’y a pas de faisceau bleu, les
faisceaux
rouge
et
vert
correspondent à une tache jaune.

Trois faisceaux rouge, vert et bleu
de forte intensité correspondent à
une tache blanche sur l’écran.

b) Des données numériques au pilotage de l’écran

Le codage des couleurs fait que pour une image « vision humaine », à une mesure issue
d’un capteur bleu correspond une commande pilotant un photophore bleu de l’écran.
Mais pour une vision SPOT, les couleurs mesurées ne correspondent pas à notre système
de vision et, comme pour obtenir une image visible par notre œil, il faut utiliser les
couleurs qu’il peut voir, il a été nécessaire de « coder » les couleurs et, en particulier,
d’attribuer une des couleurs visibles par notre œil aux données issues du capteur
infrarouge.
Structure d’une image

Une image est formée de 3
fichiers numériques : chacun de
ces fichiers pilotent une couleur
à l’écran.

Plusieurs choix sont possibles :
XS1 (mesures du vert)
? vert
XS2 (mesures du rouge)
? rouge
XS3 (mesures de l’infrarouge) ? bleu

XS1 (mesures du vert)
? vert
XS2 (mesures du rouge)
? bleu
XS3 (mesures de l’infrarouge) ? rouge

XS1 (mesures du vert)
? bleu
XS2 (mesures du rouge)
? rouge
XS3 (mesures de l’infrarouge) ? vert

Quoi que l’on fasse, les coule urs ne correspondront pas à ce que nous voyons de nos
yeux.
Un choix a été fait, au niveau international :
XS1 (mesures du vert)
? bleu
XS2 (mesures du rouge)
? vert
XS3 (mesures de l’infrarouge) ? rouge
Avec ce choix, les champs sont rouges (quand ils
sont couverts de végétation en activité) ou bleus
(quand ils sont labourés ou qu’ils viennent d’être
moissonnés), mais les fleuves, rivières, étangs,
lacs ou océans ont des couleurs qui s’étalent du
bleu clair au bleu très foncé.

VIII ) Pourquoi les champs sont-ils rouges ou bleus ?

Moyennes des valeurs
trouvées dans chaque
canal pour un champ
rouge (en noir) et pour
un champ bleu (en
bleu).

Explications :
Un champ rouge est « v u » comme un champ un peu vert, pas du tout rouge et très infrarouge.
Le codage des couleurs signifie que la couleur du champ à l’écran sera un peu bleue, pas du
tout verte et très rouge ? donc, au final, une parcelle rouge.
Un champ bleu est vu comme étant à peu près équilibré pour chaque couleur (ce qui
correspondrait à du blanc) avec une légère prédominance pour les résultats issus du capteur
vert ce qui se traduit par un léger excès de couleur bleue, et donne un champ bleu clair.

VIII ) Applications
Un champ de betteraves en Avril vient juste d’être labouré et ensemencé. C’est en fait
un sol nu.
Un champ de blé en Avril a été semé en Octobre ou Novembre de l’année précédente et
est couvert de tiges de blé en pleine croissance, hautes de 20 à 25 cm et du plus joli vert.
Par contre, en Août, un champ de blé a été moissonné et est, soit à l’état de chaume, soit
labouré pour les prochaines semailles : c’est un sol nu.
En Août, un champ de betteraves est couverts de feuilles de betterave et nous apparaît
comme une vaste étendue verte.

Champ de betteraves en avril

Champ de blé en avril

La communauté européenne utilise les images satellites pour suivre les cultures en
Europe. Des images sont acquises régulièrement.
Pour traiter et analyser une image satellite, il faut avoir des informations terrain : des
sites de 500 m de côté ont été sélectionnés dans toute l’Europe et régulièrement (au
moins deux fois par an) des équipes d’enquêteurs vont faire un relevé exhaustif de tout
ce qui pousse dans les parcelles contenues dans le périmètre délimité. Ces résultats
vérité -terrain permettent de calibrer les valeurs numériques en tenant compte de la
diversité climatique et pédologique de l’Europe et aussi des diverses pratiques
culturales.
En étudiant plusieurs images prises à des intervalles réguliers, il est possible de suivre
l’état d’une parcelle et de prévenir les risques de maladies ou de prendre conscience de
défauts d’irrigation.
Des images SPOT avec une résolution de 2,50 m (SPOT 5) commencent à être
commercialisées pour ce genre d’investigation (certaines coopératives agricoles, dans le
cadre d’actions de recherche et de développement effectuent des études de préconisation
d’engrais ou de produits phytosanitaires pour des parcelles suivies par des images
satellites en coopération avec l’Institut National de Recherche Agricole).

Le monde agricole est en pleine évolution, même si tout ne se fait pas en un jour.

Les capteurs de SPOT
doivent être recalibrés
régulièrement : ils le
sont quand le satellite
passe au -dessus des
zones enneigées du
Groënland et aussi
quand il passe audessus
des
vastes
étendues d’herbe sèche
de la Plaine de la Crau.

Le développement de nouvelles technologies ne peut faire disparaître les besoins de
connaissances du terrain.

Vraies
ou
fausses
couleurs, les images font
rêver !

Couleurs,
vraies ou fausses ?

Champs rouges,
champs bleus
sur une image
satellite
Adrien AUGE
Gaultier LAMBERT
Antoine MEYER

Lycée ROOSEVELT - REIMS

